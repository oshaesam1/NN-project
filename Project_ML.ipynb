{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dMhMHlF9nAOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa1c1bf-f0c8-4cc8-cd9d-3e5d82e77a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "import glob\n",
        "\n",
        "# Deep leearnig and machine learning libraries (Keras and scikit learn)\n",
        "from os import listdir\n",
        "from tensorflow.keras import datasets, layers, models, utils\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.python.framework import ops\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import  KFold\n",
        "# Classic libraries with python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WInxs3adnOCT"
      },
      "outputs": [],
      "source": [
        "# Settings:\n",
        "img_size = 64\n",
        "num_classes = 10\n",
        "path ='/content/drive/MyDrive/Dataset'\n",
        "\n",
        "\n",
        "\n",
        "def read_greyimg(data_file):\n",
        "    #Normalization step1 (convert image to grey)\n",
        "    img = cv2.imread(data_file,cv2.IMREAD_GRAYSCALE )\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    return img\n",
        "\n",
        "def first_normalize():\n",
        "  X = []\n",
        "  Y = [] \n",
        "  labels = listdir(path) \n",
        "  for i, label in enumerate(labels):\n",
        "          dir = path+'/'+label\n",
        "          for data_file in listdir(dir):\n",
        "              img = read_greyimg(dir+'/'+data_file)\n",
        "              X.append(img)\n",
        "              Y.append(label)\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "  Y = to_categorical(Y, num_classes)\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.8)\n",
        "  # Normalization step2 (Divide each image by 255)\n",
        "  X_train=X_train/255\n",
        "  X_test=X_test/255\n",
        "\n",
        "  #convert 3D to 2D \n",
        "  X_train  = X_train.reshape( -1, img_size*img_size)\n",
        "  X_test= X_test.reshape( -1, img_size*img_size)\n",
        "  return X_train,Y_train,X_test,Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wrY-2iSK1WOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a3a90b-c513-45a9-b793-171736467a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 5.8170 - accuracy: 0.0933\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 2.3309 - accuracy: 0.1208\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 2.2515 - accuracy: 0.1517\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 2.0678 - accuracy: 0.2533\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 1.8712 - accuracy: 0.3175\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.6687 - accuracy: 0.3775\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.6144 - accuracy: 0.3992\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 1.4490 - accuracy: 0.4800\n",
            "19/19 [==============================] - 1s 29ms/step - loss: 1.3372 - accuracy: 0.4917\n",
            "0.49166667461395264\n",
            "acc in split 1 :0.49166667461395264\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.3646 - accuracy: 0.4983\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 1.3270 - accuracy: 0.5108\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.1422 - accuracy: 0.6150\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 1.1318 - accuracy: 0.6217\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 1.0725 - accuracy: 0.6350\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.1015 - accuracy: 0.5967\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.0853 - accuracy: 0.6200\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.9445 - accuracy: 0.6725\n",
            "19/19 [==============================] - 1s 29ms/step - loss: 1.0520 - accuracy: 0.6350\n",
            "0.6349999904632568\n",
            "acc in split 2 :0.6349999904632568\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.9767 - accuracy: 0.6683\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.9147 - accuracy: 0.6833\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 1.0233 - accuracy: 0.6483\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.8751 - accuracy: 0.7100\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.8262 - accuracy: 0.7275\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.8046 - accuracy: 0.7258\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.8122 - accuracy: 0.7233\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.7732 - accuracy: 0.7533\n",
            "19/19 [==============================] - 1s 27ms/step - loss: 0.8635 - accuracy: 0.7000\n",
            "0.699999988079071\n",
            "acc in split 3 :0.699999988079071\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 2048)              8390656   \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,499,082\n",
            "Trainable params: 10,499,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "19/19 [==============================] - 1s 27ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84        68\n",
            "           1       0.84      0.64      0.72        66\n",
            "           2       0.53      0.86      0.65        49\n",
            "           3       0.68      0.92      0.78        48\n",
            "           4       0.73      0.46      0.57        71\n",
            "           5       0.78      0.91      0.84        66\n",
            "           6       0.65      0.90      0.76        61\n",
            "           7       0.92      0.18      0.30        68\n",
            "           8       0.53      0.66      0.59        44\n",
            "           9       0.79      0.71      0.75        59\n",
            "\n",
            "    accuracy                           0.70       600\n",
            "   macro avg       0.72      0.71      0.68       600\n",
            "weighted avg       0.74      0.70      0.68       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        " # first Neural Network architecture\n",
        " X_train ,Y_train,X_test,Y_test = first_normalize() \n",
        "\n",
        " ann1 = models.Sequential([\n",
        "           layers.Dense(2048,input_shape=(img_size*img_size,), activation='relu'),\n",
        "           layers.Dense(1024, activation='relu'),\n",
        "           layers.Dense(10, activation='softmax'),\n",
        " ])\n",
        "\n",
        " ann1.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Cross Validation\n",
        "X_cross=X_train\n",
        "Y_cross=Y_train\n",
        "kfolds = KFold(n_splits=3)\n",
        "i=0\n",
        "for train_index, test_index in kfolds.split(X_cross):\n",
        "    i=i+1\n",
        "    X_train_cross, X_test_cross, Y_train_cross, Y_test_cross = X_cross[train_index], X_cross[test_index],Y_cross[train_index], Y_cross[test_index]\n",
        "    ann1.fit(X_train_cross, Y_train_cross,epochs=8)\n",
        "    acc=ann1.evaluate(X_test_cross,Y_test_cross)\n",
        "    print(acc[1])\n",
        "    print(\"acc in split \"+ str(i) + \" :\"+str(acc[1]))\n",
        "\n",
        "\n",
        "\n",
        "#Evaluate model 1\n",
        "ann1.summary()\n",
        " Y_pred1 = ann1.predict(X_test_cross)\n",
        " Y_pred1 = [np.argmax(element) for element in Y_pred1]\n",
        " Y_test1 = [np.argmax(element) for element in Y_test_cross]\n",
        " print(classification_report(Y_test1, Y_pred1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5YAD1jbs5TsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93db938a-9b79-4acd-9143-80d4f777ccdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "38/38 [==============================] - 1s 8ms/step - loss: 2.3675 - accuracy: 0.1150\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.3437 - accuracy: 0.1133\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 2.3258 - accuracy: 0.1275\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.3218 - accuracy: 0.1100\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.2623 - accuracy: 0.1625\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 2.0330 - accuracy: 0.2583\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.7719 - accuracy: 0.3658\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.6361 - accuracy: 0.3967\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.6548 - accuracy: 0.3950\n",
            "acc in split 1 :0.39500001072883606\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.4951 - accuracy: 0.4683\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.4004 - accuracy: 0.4842\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.3931 - accuracy: 0.5000\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.2382 - accuracy: 0.5767\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.1858 - accuracy: 0.6008\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.0705 - accuracy: 0.6300\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 1.1639 - accuracy: 0.5800\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.0284 - accuracy: 0.6625\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0961 - accuracy: 0.6050\n",
            "acc in split 2 :0.6050000190734863\n",
            "Epoch 1/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9818 - accuracy: 0.6642\n",
            "Epoch 2/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.0097 - accuracy: 0.6467\n",
            "Epoch 3/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9029 - accuracy: 0.6825\n",
            "Epoch 4/8\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8539 - accuracy: 0.7242\n",
            "Epoch 5/8\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.8835 - accuracy: 0.6908\n",
            "Epoch 6/8\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.9412 - accuracy: 0.6717\n",
            "Epoch 7/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.7978 - accuracy: 0.7333\n",
            "Epoch 8/8\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.7793 - accuracy: 0.7392\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1254 - accuracy: 0.6217\n",
            "acc in split 3 :0.621666669845581\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 100)               409700    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 400)               40400     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 300)               120300    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 573,410\n",
            "Trainable params: 573,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "19/19 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.94      0.67        66\n",
            "           1       0.89      0.64      0.74        50\n",
            "           2       0.93      0.22      0.35        65\n",
            "           3       0.95      0.66      0.78        56\n",
            "           4       0.48      0.50      0.49        68\n",
            "           5       0.79      0.91      0.85        70\n",
            "           6       0.45      0.33      0.38        64\n",
            "           7       0.62      0.53      0.57        59\n",
            "           8       0.47      0.60      0.53        48\n",
            "           9       0.61      0.91      0.73        54\n",
            "\n",
            "    accuracy                           0.62       600\n",
            "   macro avg       0.67      0.62      0.61       600\n",
            "weighted avg       0.67      0.62      0.60       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Second Neural Network architecture\n",
        "X_train ,Y_train,X_test,Y_test = first_normalize() \n",
        "\n",
        "ann2 = models.Sequential([\n",
        "  layers.Dense(100,input_shape=(img_size*img_size,), activation='relu'),\n",
        "  layers.Dense(400,input_shape=(img_size*img_size,), activation='sigmoid'),\n",
        "  layers.Dense(300,input_shape=(img_size*img_size,), activation='sigmoid'),\n",
        "  layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "ann2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Cross Validation\n",
        "X_cross=X_train\n",
        "Y_cross=Y_train\n",
        "kfolds = KFold(n_splits=3)\n",
        "i=0\n",
        "for train_index, test_index in kfolds.split(X_cross):\n",
        "    i=i+1\n",
        "    X_train_cross, X_test_cross, Y_train_cross, Y_test_cross = X_cross[train_index], X_cross[test_index],Y_cross[train_index], Y_cross[test_index]\n",
        "    ann2.fit(X_train_cross, Y_train_cross,epochs=8)\n",
        "    acc=ann2.evaluate(X_test_cross,Y_test_cross)\n",
        "    print(\"acc in split \"+ str(i) + \" :\"+str(acc[1]))\n",
        "\n",
        "\n",
        "#Evaluate model 2\n",
        "ann2.summary()\n",
        "\n",
        "Y_pred2 = ann2.predict(X_test_cross)\n",
        "Y_pred2 = [np.argmax(element) for element in Y_pred2]\n",
        "Y_test2 = [np.argmax(element) for element in Y_test_cross]\n",
        "print(classification_report(Y_test2, Y_pred2))  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_uAr33v76Nc-"
      },
      "outputs": [],
      "source": [
        "#Train using normalized RGB image\n",
        "\n",
        "def read_rgbimg(data_file):\n",
        "    img = cv2.imread(data_file)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    return img\n",
        "def second_normalize():\n",
        "  X = []\n",
        "  Y = []\n",
        "  labels = listdir(path) \n",
        "  for i, label in enumerate(labels):\n",
        "          dir = path+'/'+label\n",
        "          for data_file in listdir(dir):\n",
        "              img = read_rgbimg(dir+'/'+data_file)\n",
        "              X.append(img)\n",
        "              Y.append(label)\n",
        "  X = np.array(X).astype('float32')\n",
        "  Y = np.array(Y)\n",
        "  Y = to_categorical(Y, num_classes) \n",
        "\n",
        "  average= X.mean(axis=0)\n",
        "  X -= average\n",
        "  X=X/255\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.8)\n",
        "  return X_train,Y_train,X_test,Y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WSqTGAjGz3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bd313b-8ff4-4379-b42e-c093d7340166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 7s 162ms/step - loss: 1.2455 - accuracy: 0.5567\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.7654 - accuracy: 0.7600\n",
            "acc in split 1 :0.7599999904632568\n",
            "38/38 [==============================] - 6s 160ms/step - loss: 0.5846 - accuracy: 0.8017\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.4265 - accuracy: 0.8567\n",
            "acc in split 2 :0.8566666841506958\n",
            "38/38 [==============================] - 6s 161ms/step - loss: 0.3522 - accuracy: 0.8958\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 0.2688 - accuracy: 0.9050\n",
            "acc in split 3 :0.9049999713897705\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 61, 61, 64)        3136      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 57600)             0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 64)                3686464   \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,690,250\n",
            "Trainable params: 3,690,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "19/19 [==============================] - 1s 42ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95        59\n",
            "           1       0.86      1.00      0.93        63\n",
            "           2       0.96      0.69      0.80        65\n",
            "           3       0.96      0.93      0.95        58\n",
            "           4       0.98      0.84      0.90        67\n",
            "           5       0.96      1.00      0.98        68\n",
            "           6       0.81      0.91      0.86        53\n",
            "           7       0.77      0.93      0.84        58\n",
            "           8       0.89      0.88      0.88        57\n",
            "           9       0.96      0.92      0.94        52\n",
            "\n",
            "    accuracy                           0.91       600\n",
            "   macro avg       0.91      0.91      0.90       600\n",
            "weighted avg       0.91      0.91      0.90       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CNN model\n",
        "X_train ,Y_train,X_test,Y_test = second_normalize() \n",
        "\n",
        "cnn1 = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=(4, 4), activation='relu', input_shape=(img_size,img_size,3)),\n",
        "    layers.MaxPooling2D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "cnn1.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Cross Validation\n",
        "X_cross=X_train\n",
        "Y_cross=Y_train\n",
        "kfolds = KFold(n_splits=3)\n",
        "i = 0\n",
        "for train_index, test_index in kfolds.split(X_cross):\n",
        "    i = i+1\n",
        "    X_train_cross, X_test_cross, Y_train_cross, Y_test_cross = X_cross[train_index], X_cross[test_index],Y_cross[train_index], Y_cross[test_index]\n",
        "    cnn1.fit(X_train_cross, Y_train_cross)\n",
        "    acc=cnn1.evaluate(X_test_cross,Y_test_cross)\n",
        "    print(\"acc in split \"+ str(i) + \" :\"+str(acc[1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Evaluate cnn\n",
        "cnn1.summary()\n",
        "\n",
        "Y_pred = cnn1.predict(X_test_cross)\n",
        "Y_pred = [np.argmax(element) for element in Y_pred]\n",
        "Y_test = [np.argmax(element) for element in Y_test_cross]\n",
        "print(classification_report(Y_test, Y_pred))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TCdW61QB0rCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d3ae49-6f65-4218-af68-0422e14bd5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc =0.8558758314855875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95        52\n",
            "           1       0.93      0.87      0.90        47\n",
            "           2       0.84      0.89      0.86        46\n",
            "           3       1.00      0.82      0.90        50\n",
            "           4       0.76      0.72      0.74        43\n",
            "           5       0.92      0.97      0.94        59\n",
            "           6       0.75      0.93      0.83        41\n",
            "           7       0.77      0.66      0.71        41\n",
            "           8       0.73      0.77      0.75        35\n",
            "           9       0.89      0.86      0.88        37\n",
            "\n",
            "    accuracy                           0.86       451\n",
            "   macro avg       0.85      0.85      0.85       451\n",
            "weighted avg       0.86      0.86      0.86       451\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SVM vs NN \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train ,Y_train,X_test,Y_test = second_normalize() \n",
        "\n",
        "Y_train=np.argmax(Y_train,axis=1)\n",
        "Y_test=np.argmax(Y_test,axis=1)\n",
        "\n",
        "\n",
        "X_train  = X_train.reshape( -1, img_size*img_size*3)#in case of rgb image \n",
        "X_test= X_test.reshape( -1, img_size*img_size*3)  \n",
        "\n",
        "svm = SVC() \n",
        "svm.fit(X_train,Y_train)\n",
        "score = svm.score(X_test,Y_test)\n",
        "Y_predict= svm.predict(X_test)\n",
        "print(\"acc =\"+str(score))\n",
        "print(classification_report(Y_test, Y_predict))\n",
        " \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}